{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from linetimer import CodeTimer\n",
    "from multiple_logging import setup_logger\n",
    "import datetime\n",
    "\n",
    "from utils import convert_ids_to_ordered, MovingAverage\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxon/anaconda3/envs/core_ds/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "aspects = pd.read_csv('data/aspects.csv').set_index(\"aspect_id\")\n",
    "features = pd.read_csv('data/features.csv').set_index('feature_id')\n",
    "organizations = pd.read_csv('data/organisations.csv').set_index('org_id')\n",
    "reviews = pd.read_csv('data/reviews.csv')\n",
    "rubrics = pd.read_csv('data/rubrics.csv').set_index('rubric_id')\n",
    "test_users = pd.read_csv('data/test_users.csv').set_index('user_id')\n",
    "users = pd.read_csv('data/users.csv').set_index('user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews[reviews.rating.notna()]\n",
    "reviews['rating'] = reviews['rating'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ordered, orgs_ordered, reviews_ordered = convert_ids_to_ordered(users, organizations, reviews)\n",
    "n_users = len(users_ordered)\n",
    "n_orgs = len(orgs_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split_day = 1050\n",
    "train_reviews = reviews_ordered[reviews_ordered.ts < validation_split_day]\n",
    "test_reviews = reviews_ordered[reviews_ordered.ts >= validation_split_day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 3037917/3037917 [00:02<00:00, 1268425.06it/s]\n"
     ]
    }
   ],
   "source": [
    "fast_train_reviews = {}\n",
    "for line in tqdm(train_reviews.values):\n",
    "    fast_train_reviews[(line[3], line[4])] = line[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews_array = train_reviews[['ordered_id_user', 'ordered_id_org', 'rating']].values\n",
    "test_reviews_array = test_reviews[['ordered_id_user', 'ordered_id_org', 'rating']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_logger = setup_logger('main_logger', 'logs/binary_als_experiments.log')\n",
    "detailed_logger = setup_logger('detailed_logger', 'logs/binary_als_experiments_detailed.log')\n",
    "pivot_logger = setup_logger('pivot_logger', 'logs/pivots_nans.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_rated_pair():\n",
    "    user_id = np.random.randint(n_users)\n",
    "    org_id = np.random.randint(n_orgs)\n",
    "    while (user_id, org_id) in fast_train_reviews:\n",
    "        user_id = np.random.randint(n_users)\n",
    "        org_id = np.random.randint(n_orgs)\n",
    "    return user_id, org_id  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(\n",
    "        Ps: np.ndarray,\n",
    "        Qs: np.ndarray,\n",
    "        bias: float,\n",
    "        neg_example_coef: int,\n",
    "    ) -> float:\n",
    "    losses = []\n",
    "    for i, review in enumerate(test_reviews_array):\n",
    "        user_id, org_id, label = review\n",
    "        label = int(label >= 4.0)\n",
    "        probability = sigmoid(Ps[user_id].dot(Qs[org_id]) + bias)\n",
    "        loss = -(label * np.log(probability) + (1 - label) * np.log(1 - probability))\n",
    "        losses.append(loss)\n",
    "        \n",
    "    for i in range(len(test_reviews_array) * neg_example_coef):\n",
    "        user_id, org_id = get_not_rated_pair()\n",
    "        label = 0\n",
    "        probability = sigmoid(Ps[user_id].dot(Qs[org_id]) + bias)\n",
    "        loss = -(label * np.log(probability) + (1 - label) * np.log(1 - probability))\n",
    "        losses.append(loss)\n",
    "    \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_review(\n",
    "        user_id: np.ndarray, \n",
    "        org_id: np.ndarray,       \n",
    "        label: int,\n",
    "        Ps: np.ndarray,\n",
    "        Qs: np.ndarray,\n",
    "        bias: float,  \n",
    "        learning_rate: float = 0.2,\n",
    "        C: float = 0.0,\n",
    "        dropout_rate: float = 0.0,\n",
    "    ):\n",
    "    latent_size = Ps.shape[1]\n",
    "    # dropout part\n",
    "    bitmask = np.random.choice([True, False], size=(latent_size,), p=[1-dropout_rate, dropout_rate])\n",
    "    multiplier = latent_size / max(1, np.sum(bitmask))\n",
    "    P = Ps[user_id] * bitmask * multiplier\n",
    "    Q = Qs[org_id] * bitmask\n",
    "    # forward pass\n",
    "    pivot = P.dot(Q) + bias\n",
    "    prob = sigmoid(pivot)\n",
    "    loss = -(label * np.log(prob) + (1 - label) * np.log(1 - prob))\n",
    "    # backward pass\n",
    "    pivot_grad = -label * (1 - prob) + (1 - label) * prob\n",
    "    Ps_grad = learning_rate * (pivot_grad * Q  + P * C)\n",
    "    Qs_grad = learning_rate * (pivot_grad * P + Q * C)\n",
    "    bias_grad = learning_rate * pivot_grad\n",
    "    # parameters update\n",
    "    Ps[user_id] -= Ps_grad\n",
    "    Qs[org_id] -= Qs_grad\n",
    "    bias -= bias_grad\n",
    "    \n",
    "    Qs[org_id][Qs[org_id] < 0] = 0.01\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        epochs: int = 7,\n",
    "        log_every: int = 1000000,\n",
    "        neg_example_coef: int = 5,\n",
    "        **kwargs,\n",
    "    ) -> float:\n",
    "    message = (f\"Experiments setup: Epochs {epochs}, log_every {log_every}, latent_size {kwargs['Ps'].shape[1]}, \"\n",
    "               f\"learning rate {kwargs['learning_rate']}, dropout {kwargs['dropout_rate']}, C {kwargs['C']}, \"\n",
    "               f\"neg_example_coef {neg_example_coef}\")\n",
    "    main_logger.info(message)\n",
    "    detailed_logger.info(message)\n",
    "    \n",
    "    average_loss = MovingAverage(1 / log_every, 1)\n",
    "    for epoch in range(epochs):\n",
    "        detailed_logger.info(f\"Epoch {epoch}\")\n",
    "        pivot_logger.info(f\"{np.max(kwargs['Qs'])}, {np.min(kwargs['Qs'])}, {np.max(kwargs['Ps'])}, {np.min(kwargs['Ps'])}\")\n",
    "        for i, review in enumerate(train_reviews_array):\n",
    "            user_id, org_id, label = review\n",
    "            label = int(label >= 4.0)\n",
    "            loss = train_single_review(user_id, org_id, label, **kwargs)\n",
    "            average_loss.add(loss)\n",
    "            \n",
    "            for _ in range(neg_example_coef):\n",
    "                user_id, org_id = get_not_rated_pair()\n",
    "                label = 0\n",
    "                loss = train_single_review(user_id, org_id, label, **kwargs)\n",
    "                average_loss.add(loss)\n",
    "                \n",
    "            if i % log_every == 0:\n",
    "                detailed_logger.info(f\"Iteration {i:07d}: Train loss {average_loss}\", )\n",
    "            \n",
    "        test_loss = test_model(Ps, Qs, bias, neg_example_coef)\n",
    "        main_logger.info(f\"Epoch {epoch}: Train loss {average_loss}, Test loss {test_loss}\")\n",
    "        detailed_logger.info(f\"Test loss {test_loss}\")\n",
    "        with open(f\"logs/model{_id}.pickle\", 'wb') as file:\n",
    "            pickle.dump({\n",
    "                \"Ps\": kwargs[\"Ps\"],\n",
    "                \"Qs\": kwargs[\"Qs\"],\n",
    "                \"bias\": kwargs[\"bias\"],\n",
    "            },\n",
    "            file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 8\n",
    "Ps = np.random.randn(len(users), latent_size) / latent_size\n",
    "Qs = np.random.randn(len(organizations), latent_size) / latent_size + 1\n",
    "bias = np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = np.random.randint(1e16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_logger.info(f'\\n\\n\\nStarting new experiment, ID: {_id}')\n",
    "detailed_logger.info(f'\\n\\n\\nStarting new experiment, ID: {_id}')\n",
    "train_model(Ps=Ps, Qs=Qs, bias=bias, C=0.2, dropout_rate=0.0, epochs=50, log_every=1000000, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = test_users.join(users_ordered)\n",
    "msk_mask = np.array(orgs_ordered.city == 'msk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16967it [01:08, 246.03it/s]\n"
     ]
    }
   ],
   "source": [
    "targets = []\n",
    "for user_id, user_city in tqdm(zip(test_users.ordered_id, test_users.city)):\n",
    "    pivots = Ps[user_id] @ Qs.T\n",
    "    if user_city == 'spb':\n",
    "        pivots[msk_mask] = -999999\n",
    "    if user_city == 'msk':\n",
    "        pivots[~msk_mask] = -999999\n",
    "    best_orgs_ordered_ids = pivots.argsort()[-20:]\n",
    "    best_orgs_native_ids = ' '.join(\n",
    "        reversed(list(map(str, orgs_ordered.index[best_orgs_ordered_ids])))\n",
    "    )\n",
    "    targets.append(best_orgs_native_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'target': targets}, index=test_users.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.mnap import compute_mnap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(f'submissions/id{_id}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16967it [00:00, 19001.52it/s]\n"
     ]
    }
   ],
   "source": [
    "res = compute_mnap(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_logger.info(f'MNAP: {res}')\n",
    "detailed_logger.info(f'MNAP: {res}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "core_ds",
   "language": "python",
   "name": "core_ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
